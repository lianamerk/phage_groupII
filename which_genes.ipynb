{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c212a6a4-55d5-4c1d-aa3c-8b7105b3d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scripts\n",
    "import os\n",
    "import subprocess\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32c8fbd-d31a-4f76-8384-00bf9e3de658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts' from '/net/holy-nfsisilon/ifs/rc_labs/eddy_lab/users/lmerk/phage_groupII/scripts.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d629c7f1-5487-4edf-85f3-7a0cfbb1341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "# Infernal subdir\n",
    "infernal_dir = os.path.join(data_dir, 'infernal/')\n",
    "g1_intron_hits = os.path.join(infernal_dir, 'g1_intron_millard.tblout')\n",
    "g2_intron_hits = os.path.join(infernal_dir, 'g2_intron_millard.tblout')\n",
    "\n",
    "# Genomes subdir\n",
    "genomes_dir = os.path.join(data_dir, 'genomes/')\n",
    "metadata_dir = os.path.join(genomes_dir, 'inphared_metadata/')\n",
    "metadata_path = os.path.join(metadata_dir, '14Dec2023_data.tsv')\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t').rename(columns={'Accession': 'target_name'})\n",
    "genbank_dir = os.path.join(genomes_dir, 'groupII_millard/')\n",
    "actual_genomes = pd.read_csv(f'{genomes_dir}actual_genomes.txt', header=None)[0].unique()\n",
    "\n",
    "# Window and defense\n",
    "window_dir = os.path.join(genomes_dir, 'gII_intron_5kb_windows/')\n",
    "bakta_dir = os.path.join(data_dir, 'bakta_output')\n",
    "pharokka_dir = os.path.join(data_dir, \"pharokka_output\")\n",
    "defense_dir = os.path.join(data_dir, 'defensefinder/bakta_defense')\n",
    "\n",
    "# Script output subdir\n",
    "script_output = os.path.join(data_dir, 'script_output/')\n",
    "genbank_out_directory = os.path.join(script_output, \"updated_genomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0281d400-073f-4c48-8f6e-5c804c5f9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9308b0-91da-43c9-a125-8a15d4efd1d9",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e25fa5-58e0-4be3-8ae8-e274e3b82b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dereplicating group I...\n",
      "Saving group I...\n",
      "Collapsing group II...\n",
      "Saving group II...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if preprocess:\n",
    "    g1_hits = scripts.extract_hit_df(g1_intron_hits)\n",
    "    g2_hits = scripts.extract_hit_df(g2_intron_hits)\n",
    "\n",
    "    g1_df = pd.merge(g1_hits, metadata, on='target_name', how='left')\n",
    "    g2_df = pd.merge(g2_hits, metadata, on='target_name', how='left')\n",
    "    \n",
    "    print('Dereplicating group I...')\n",
    "    g1_hits_pass, g1_hits_fail = scripts.dereplicate_hits(g1_df)\n",
    "\n",
    "    print('Saving group I...')\n",
    "    # Save all the hits\n",
    "    g1_df.sort_values('target_name').to_csv(f'{script_output}g1_df.csv', index=False)\n",
    "    # Save the ones that didn't pass the filter\n",
    "    g1_hits_fail.to_csv(f'{script_output}g1_hits_fail.csv', index=False)\n",
    "    # Clean the passes, add the intronID, then save it\n",
    "    g1_hits_pass = g1_hits_pass.sort_values(by=['target_name', 'seq_from'])\n",
    "    g1_hits_pass['intronID'] = g1_hits_pass['target_name'] + '_I_' + g1_hits_pass['seq_from'].astype(str)\n",
    "    column_order = ['intronID'] + [col for col in g1_hits_pass.columns if col != 'intronID']\n",
    "    g1_hits_pass = g1_hits_pass[column_order]\n",
    "    g1_hits_pass.to_csv(f'{script_output}g1_hits_pass.csv', index=False)\n",
    "    \n",
    "    \n",
    "    print('Collapsing group II...')\n",
    "    g2_hits_pass = scripts.collapse_hits(g2_df)\n",
    "    \n",
    "    print('Saving group II...')\n",
    "    g2_hits_pass = g2_hits_pass.sort_values(by=['target_name', 'seq_from'])\n",
    "    g2_hits_pass['intronID'] = g2_hits_pass['target_name'] + '_II_' + g2_hits_pass['seq_from'].astype(str)\n",
    "    column_order = ['intronID'] + [col for col in g2_hits_pass.columns if col != 'intronID']\n",
    "    g2_hits_pass = g2_hits_pass[column_order]\n",
    "    g2_hits_pass.to_csv(f'{script_output}g2_hits_pass.csv', index=False)\n",
    "\n",
    "    # Save all the hits\n",
    "    g2_df = g2_df.sort_values(by=['target_name', 'seq_from'])\n",
    "    g2_df['intronID'] = g2_df['target_name'] + '_II_' + g2_df['seq_from'].astype(str)\n",
    "    column_order = ['intronID'] + [col for col in g2_df.columns if col != 'intronID']\n",
    "    g2_df = g2_df[column_order]\n",
    "    g2_df.to_csv(f'{script_output}g2_df.csv', index=False)\n",
    "    print('Done!')\n",
    "    \n",
    "else:\n",
    "    g1_df = pd.read_csv(f'{script_output}g1_df.csv')\n",
    "    g2_df = pd.read_csv(f'{script_output}g2_df.csv')\n",
    "\n",
    "    g1_hits_pass = pd.read_csv(f'{script_output}g1_hits_pass.csv')\n",
    "    g2_hits_pass = pd.read_csv(f'{script_output}g2_hits_pass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f2f49d-d238-485c-b33b-b9b9d574e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will submit jobs to slurm to hmmscan the surrounding window\n",
    "# The genomes should be indexed (i.e. contain a .idx file in the dir)\n",
    "# If not, you can use esl-index.sh\n",
    "\n",
    "if preprocess:\n",
    "    scripts.hmmscan_window(g2_df, genbank_dir, window_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1b1daf-86f4-4d51-8688-498a42f57ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you need to make sure all your jobs from above have finished before running this\n",
    "# You also need to run the following bash scripts before running this:\n",
    "# pharokka.sh in pharokka env to generate annotations\n",
    "# bakta.sh in bakta env to generate annotations\n",
    "# defensefinder.sh in defensefinder env to get defense\n",
    "\n",
    "if preprocess:\n",
    "    all_defense_hits = scripts.combine_defense(g2_df, bakta_dir, defense_dir)\n",
    "    all_hit_df = scripts.hit_to_genome_with_domtbl(g2_df, window_dir, genbank_dir)\n",
    "    all_hit_df_derep = all_hit_df.loc[all_hit_df['genome'].isin(actual_genomes)]\n",
    "    all_hit_df_derep.to_csv(f'{script_output}g2_genes_top3_5kb_with_locs.csv', index=False)\n",
    "    scripts.combine_genbanks(all_hit_df_derep, pharokka_dir, bakta_dir, genbank_out_directory, actual_genomes)\n",
    "    scripts.update_genbank(genbank_out_directory, all_hit_df_derep, g1_hits_pass, g2_df, all_defense_hits)\n",
    "else:\n",
    "    all_hit_df_derep =  pd.read_csv(f'{script_output}g2_genes_top3_5kb_with_locs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jupyter_3.6]",
   "language": "python",
   "name": "conda-env-.conda-jupyter_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
