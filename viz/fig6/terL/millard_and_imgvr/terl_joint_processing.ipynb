{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa033618-1bb8-4459-95c5-c2c388c1190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Function to read HMMER .tblout file into a pandas DataFrame\n",
    "def read_tblout_to_dataframe(tblout_file):\n",
    "    # Define column names based on HMMER .tblout format\n",
    "    column_names = [\n",
    "        'target_name', 'accession', 'query_name', 'accession_query', \n",
    "        'e_value', 'score', 'bias', 'e_value_best_dom', \n",
    "        'score_best_dom', 'bias_best_dom', 'exp', 'reg', \n",
    "        'clu', 'ov', 'env', 'dom', 'rep', 'inc', 'description'\n",
    "    ]\n",
    "    \n",
    "    # Read the file, skipping lines starting with '#'\n",
    "    data = []\n",
    "    with open(tblout_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith(\"#\"):  # Skip comment lines\n",
    "                # Split the line by any whitespace and limit to the first 18 fields\n",
    "                fields = line.strip().split(maxsplit=18)\n",
    "                data.append(fields)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    \n",
    "    df['genome'] = df['target_name'].str.split('_CDS').str[0]\n",
    "\n",
    "    # Convert the 'e_value' column to float for numerical filtering\n",
    "    df['e_value'] = pd.to_numeric(df['e_value'], errors='coerce')\n",
    "        \n",
    "    # Step 1: Identify duplicated genomes\n",
    "    duplicated_genomes = df[df['genome'].duplicated(keep=False)]\n",
    "\n",
    "    # Step 2: For duplicated genomes, keep only the row with the lowest 'e_value'\n",
    "    lowest_evalue_duplicates = duplicated_genomes.loc[duplicated_genomes.groupby('genome')['e_value'].idxmin()]\n",
    "\n",
    "    # Step 3: Get the rows where genome is not duplicated (keep as they are)\n",
    "    unique_genomes = df[~df['genome'].duplicated(keep=False)]\n",
    "\n",
    "    # Step 4: Combine both unique genomes and lowest e_value duplicates\n",
    "    final_df = pd.concat([lowest_evalue_duplicates, unique_genomes], ignore_index=True)\n",
    "\n",
    "    return final_df.loc[final_df['e_value'] <= 0.001]\n",
    "\n",
    "tblout_file = 'PF03237_millard_imgvr.tblout'\n",
    "df = read_tblout_to_dataframe(tblout_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9ad429-ff41-42cf-b484-228051963349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.genome.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1ef936-8117-404e-9218-efbb7114d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.genome.to_csv('headers.txt', index=False, header=False)\n",
    "tblout_final = df.loc[df.genome.isin(df.genome.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e18708-1e38-4e68-9fb8-3705c7ff05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify duplicated genomes\n",
    "duplicated_genomes = tblout_final[tblout_final['e_value'].duplicated(keep=False)]\n",
    "\n",
    "# Step 2: For duplicated genomes, keep only the row with the lowest 'e_value'\n",
    "lowest_evalue_duplicates = duplicated_genomes.loc[duplicated_genomes.groupby('genome')['e_value'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a56ef3-8e25-4067-a792-d20ca71651fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_evalue_duplicates.target_name.to_csv('proteins_to_pull.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41b3db7-4db5-4e49-bb6e-ea158e642cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!esl-sfetch -f \"/n/eddy_lab/users/lmerk/phage_groupII/IMGVR/all_imgvr_hit_genome_annotations/phanotate.faa\" \"proteins_to_pull.txt\" > \"Terminase_6N_imgvr.faa\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e4e53-5a57-4e89-bd12-29f0bbb2be41",
   "metadata": {},
   "source": [
    "## Run clustering on these proteins, then choose a representative from each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea451d-1c41-4d72-b3d8-c02fb334a2a5",
   "metadata": {},
   "source": [
    "This is done with esl-msacluster with a binary to determine PID that yields 30 clusters. For this it was 17.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b983989-d0db-49e7-89f5-e2f86a33cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = pickle.load(open('terL_30_clusters.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92c36fc-8020-4f8c-abc7-7f448cdc9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_per_cluster = {key: values[0] for key, values in cluster_dict.items()}\n",
    "imgvr_reps = list(one_per_cluster.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7efed29-6c75-4540-81b0-2cd027479381",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgvr_rep_df = df.loc[df.genome.isin(imgvr_reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ceebc6-8ae8-4bae-be5e-5335bd6592c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgvr_rep_df.target_name.to_csv('proteins_to_pull_cluster_rep.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9acc9eef-08b2-45b5-9770-38bb5b80bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!esl-sfetch -f \"/n/eddy_lab/users/lmerk/phage_groupII/IMGVR/all_imgvr_hit_genome_annotations/phanotate.faa\" \"proteins_to_pull_cluster_rep.txt\" > \"Terminase_6N_imgvr_cluster_rep.faa\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e888234-5760-47f1-886e-c66b9d11b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers renamed and saved to Terminase_6N_imgvr_cluster_rep_single_name.faa\n"
     ]
    }
   ],
   "source": [
    "# Input and output file paths\n",
    "input_faa = \"Terminase_6N_imgvr_cluster_rep.faa\"\n",
    "output_faa = \"Terminase_6N_imgvr_cluster_rep_single_name.faa\"\n",
    "\n",
    "# Function to rename headers\n",
    "def rename_headers(fasta_file, output_file):\n",
    "    with open(fasta_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                # Extract only the part before the first underscore\n",
    "                new_header = re.match(r\">(.*?)_CDS\", line).group(1)\n",
    "                outfile.write(f\">{new_header}\\n\")\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "\n",
    "# Run the renaming function\n",
    "rename_headers(input_faa, output_faa)\n",
    "\n",
    "print(f\"Headers renamed and saved to {output_faa}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
